{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('m0gnonnjv9447i2hps7s9u7ceir7laro', 1678401197, '2023-03-09 22:33:17')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pyTigerGraph as tg\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphSAGE, GCN, Node2Vec, GAT\n",
    "from pyTigerGraph.gds.metrics import Accumulator, Accuracy, BinaryPrecision, BinaryRecall\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import TigerGraph instance config\n",
    "os.chdir('../config/')\n",
    "with open('tigergraph.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Connection parameters\n",
    "hostName = config['host']\n",
    "secret = '5kn71rhu7612ma7msfcvtm6d9de173gk'\n",
    "\n",
    "conn = tg.TigerGraphConnection(host=hostName, gsqlSecret=secret, graphname=\"Ethereum2\")\n",
    "conn.getToken(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices in training set: 623\n",
      "Number of vertices in test set: 267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Wallet': 86622}, {'sent_eth': 106083, 'reverse_sent_eth': 106083})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split nodes into train/test/validation sets\n",
    "# split = conn.gds.vertexSplitter(is_train=0.6, is_test=0.2, is_valid=0.2)\n",
    "# split.run()\n",
    "print(\n",
    "    \"Number of vertices in training set:\",\n",
    "    conn.getVertexCount(\"Wallet\", where=\"is_train!=0\"),\n",
    ")\n",
    "print(\n",
    "    \"Number of vertices in test set:\",\n",
    "    conn.getVertexCount(\"Wallet\", where=\"is_test!=0\"),\n",
    ")\n",
    "conn.getVertexCount('*'),conn.getEdgeCount('*'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train/test/validation data from TigerGraph\n",
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats=[\"in_degree\",\"out_degree\",\"total_sent\",\"send_min\",\"recv_amount\",\"recv_min\",\"pagerank\"],\n",
    "    v_out_labels=['label'],\n",
    "    v_extra_feats=['is_train','is_test'],\n",
    "    output_format = \"PyG\"\n",
    ")\n",
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 106083], x=[86622, 7], y=[86622], is_train=[86622], is_test=[86622])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters for model training\n",
    "hp = {\"hidden_dim\": 512,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.05,\n",
    "    \"lr\": 0.0075,\n",
    "    \"l2_penalty\": 5e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model = GCN(\n",
    "    in_channels=7,\n",
    "    hidden_channels=hp[\"hidden_dim\"],\n",
    "    num_layers=hp[\"num_layers\"],\n",
    "    out_channels=7,\n",
    "    dropout=hp[\"dropout\"],\n",
    "    heads=8\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Train Loss: 123.2926, Test Loss: 99.5436, Train Accuracy: 0.2360, Test Accuracy: 0.2322\n",
      "Epoch: 01, Train Loss: 278.1959, Test Loss: 277.4247, Train Accuracy: 0.4912, Test Accuracy: 0.5206\n",
      "Epoch: 02, Train Loss: 374.3616, Test Loss: 376.3057, Train Accuracy: 0.4912, Test Accuracy: 0.5206\n",
      "Epoch: 03, Train Loss: 374.9960, Test Loss: 374.8954, Train Accuracy: 0.5024, Test Accuracy: 0.5318\n",
      "Epoch: 04, Train Loss: 319.2099, Test Loss: 316.0376, Train Accuracy: 0.5185, Test Accuracy: 0.5543\n",
      "Epoch: 05, Train Loss: 226.1408, Test Loss: 218.4551, Train Accuracy: 0.5425, Test Accuracy: 0.5880\n",
      "Epoch: 06, Train Loss: 104.3793, Test Loss: 95.1380, Train Accuracy: 0.5698, Test Accuracy: 0.5955\n",
      "Epoch: 07, Train Loss: 81.8119, Test Loss: 53.5573, Train Accuracy: 0.6180, Test Accuracy: 0.6142\n",
      "Epoch: 08, Train Loss: 151.3272, Test Loss: 118.6835, Train Accuracy: 0.5425, Test Accuracy: 0.5169\n",
      "Epoch: 09, Train Loss: 40.7220, Test Loss: 31.0490, Train Accuracy: 0.6324, Test Accuracy: 0.6105\n",
      "Epoch: 10, Train Loss: 56.2258, Test Loss: 50.6793, Train Accuracy: 0.6453, Test Accuracy: 0.6517\n",
      "Epoch: 11, Train Loss: 87.5622, Test Loss: 85.1220, Train Accuracy: 0.6051, Test Accuracy: 0.6367\n",
      "Epoch: 12, Train Loss: 90.3737, Test Loss: 91.7759, Train Accuracy: 0.6035, Test Accuracy: 0.6330\n",
      "Epoch: 13, Train Loss: 73.3400, Test Loss: 77.9084, Train Accuracy: 0.6228, Test Accuracy: 0.6517\n",
      "Epoch: 14, Train Loss: 42.6911, Test Loss: 48.5664, Train Accuracy: 0.6485, Test Accuracy: 0.6742\n",
      "Epoch: 15, Train Loss: 131.6670, Test Loss: 104.0447, Train Accuracy: 0.7464, Test Accuracy: 0.7266\n",
      "Epoch: 16, Train Loss: 21.2811, Test Loss: 19.7172, Train Accuracy: 0.7769, Test Accuracy: 0.7116\n",
      "Epoch: 17, Train Loss: 19.1067, Test Loss: 15.6444, Train Accuracy: 0.7368, Test Accuracy: 0.6779\n",
      "Epoch: 18, Train Loss: 33.7397, Test Loss: 21.0483, Train Accuracy: 0.7255, Test Accuracy: 0.6779\n",
      "Epoch: 19, Train Loss: 34.7761, Test Loss: 26.3320, Train Accuracy: 0.7111, Test Accuracy: 0.6779\n",
      "Epoch: 20, Train Loss: 42.3325, Test Loss: 29.8387, Train Accuracy: 0.7111, Test Accuracy: 0.6667\n",
      "Epoch: 21, Train Loss: 45.0523, Test Loss: 29.7850, Train Accuracy: 0.7127, Test Accuracy: 0.6779\n",
      "Epoch: 22, Train Loss: 48.6208, Test Loss: 25.8438, Train Accuracy: 0.7159, Test Accuracy: 0.6966\n",
      "Epoch: 23, Train Loss: 43.6474, Test Loss: 22.2204, Train Accuracy: 0.7159, Test Accuracy: 0.7004\n",
      "Epoch: 24, Train Loss: 46.6336, Test Loss: 26.9520, Train Accuracy: 0.7111, Test Accuracy: 0.6742\n",
      "Epoch: 25, Train Loss: 41.5252, Test Loss: 21.0110, Train Accuracy: 0.7271, Test Accuracy: 0.7041\n",
      "Epoch: 26, Train Loss: 40.9762, Test Loss: 22.5941, Train Accuracy: 0.7207, Test Accuracy: 0.6966\n",
      "Epoch: 27, Train Loss: 36.8442, Test Loss: 18.2723, Train Accuracy: 0.7512, Test Accuracy: 0.7116\n",
      "Epoch: 28, Train Loss: 34.2598, Test Loss: 17.4852, Train Accuracy: 0.7624, Test Accuracy: 0.7191\n",
      "Epoch: 29, Train Loss: 29.2035, Test Loss: 17.0094, Train Accuracy: 0.7785, Test Accuracy: 0.7191\n"
     ]
    }
   ],
   "source": [
    "logs = {}\n",
    "data = data.to(device)\n",
    "for epoch in range(30):\n",
    "    # Train\n",
    "    model.train()\n",
    "    acc = Accuracy()\n",
    "    # Forward pass\n",
    "    out = model(data.x.float(), data.edge_index)\n",
    "    # Calculate loss\n",
    "    loss = F.cross_entropy(out[data.is_train].float(), data.y[data.is_train].long())\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Evaluate\n",
    "    val_acc = Accuracy()\n",
    "    with torch.no_grad():\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc.update(pred[data.is_train], data.y[data.is_train])\n",
    "        valid_loss = F.cross_entropy(out[data.is_test].float(), data.y[data.is_test].long())\n",
    "        val_acc.update(pred[data.is_test], data.y[data.is_test])\n",
    "    # Logging\n",
    "    logs[\"loss\"] = loss.item()\n",
    "    logs[\"test_loss\"] = valid_loss.item()\n",
    "    logs[\"acc\"] = acc.value\n",
    "    logs[\"test_acc\"] = val_acc.value\n",
    "    print(\n",
    "        \"Epoch: {:02d}, Train Loss: {:.4f}, Test Loss: {:.4f}, Train Accuracy: {:.4f}, Test Accuracy: {:.4f}\".format(\n",
    "            epoch, logs[\"loss\"], logs[\"test_loss\"], logs[\"acc\"], logs[\"test_acc\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7491\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = Accuracy()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x.float(), data.edge_index).argmax(dim=1)\n",
    "    acc.update(pred[data.is_test], data.y[data.is_test])\n",
    "print(\"Final Test Accuracy: {:.4f}\".format(acc.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance:\n",
    "\n",
    "# Baseline: \n",
    "\n",
    "# GCN around 0.7079% with 30 epochs and hp = {\"hidden_dim\": 128,\n",
    "    # \"num_layers\": 2,\n",
    "    # \"dropout\": 0.05,\n",
    "    # \"lr\": 0.005,\n",
    "    # \"l2_penalty\": 5e-5}\n",
    "\n",
    "# GraphSAGE around 0.7228% with 30 epochs and hp = {\"hidden_dim\": 128,\n",
    "    # \"num_layers\": 2,\n",
    "    # \"dropout\": 0.05,\n",
    "    # \"lr\": 0.0075,\n",
    "    # \"l2_penalty\": 5e-5}\n",
    "\n",
    "# GAT around 0.7191 with hp = {\"hidden_dim\": 128,\n",
    "    # \"num_layers\": 2,\n",
    "    # \"dropout\": 0.05,\n",
    "    # \"lr\": 0.0075,\n",
    "    # \"l2_penalty\": 5e-5}\n",
    "    # heads = 8\n",
    "\n",
    "    # same training loops for GraphSAGE, GAT, GCN\n",
    "\n",
    "# Node2Vec - \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TAGCN - around .74%\n",
    "\n",
    "\n",
    "# Deep Graph Infomax - DGI ROUGLY 73.5% can be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.nn import DeepGraphInfomax, GCNConv\n",
    "\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels):\n",
    "#         super().__init__()\n",
    "#         self.conv = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "#         self.prelu = nn.PReLU(hidden_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = self.conv(x, edge_index)\n",
    "#         x = self.prelu(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# def corruption(x, edge_index):\n",
    "#     return x[torch.randperm(x.size(0))], edge_index\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = DeepGraphInfomax(\n",
    "#     hidden_channels=512, encoder=Encoder(data.num_features, 512),\n",
    "#     summary=lambda z, *args, **kwargs: torch.sigmoid(z.mean(dim=0)),\n",
    "#     corruption=corruption).to(device)\n",
    "# data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     pos_z, neg_z, summary = model(data.x.float(), data.edge_index)\n",
    "#     loss = model.loss(pos_z, neg_z, summary)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "\n",
    "# for epoch in range(1, 30):\n",
    "#     loss = train()\n",
    "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     model.eval()\n",
    "#     z, _, _ = model(data.x.float(), data.edge_index)\n",
    "#     acc = model.test(z[data.is_train], data.y[data.is_train],\n",
    "#                      z[data.is_test], data.y[data.is_test], max_iter=150, C=100000)\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = test()\n",
    "# print(f'Final Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Flickr\n",
    "from torch_geometric.loader import GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "\n",
    "data = data2\n",
    "row, col = data.edge_index\n",
    "data.edge_weight = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.\n",
    "\n",
    "\n",
    "loader = GraphSAINTRandomWalkSampler(data, batch_size=6000, walk_length=2,\n",
    "                                     num_steps=5, sample_coverage=100,\n",
    "                                     num_workers=4)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        in_channels = data.num_node_features\n",
    "        out_channels = 2\n",
    "        self.conv1 = GraphConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(3 * hidden_channels, out_channels)\n",
    "\n",
    "    def set_aggr(self, aggr):\n",
    "        self.conv1.aggr = aggr\n",
    "        self.conv2.aggr = aggr\n",
    "        self.conv3.aggr = aggr\n",
    "\n",
    "    def forward(self, x0, edge_index, edge_weight=None):\n",
    "        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))\n",
    "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
    "        x2 = F.relu(self.conv2(x1, edge_index, edge_weight))\n",
    "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
    "        x3 = F.relu(self.conv3(x2, edge_index, edge_weight))\n",
    "        x3 = F.dropout(x3, p=0.2, training=self.training)\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "        x = self.lin(x)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(hidden_channels=512).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "use_normalization=False\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    model.set_aggr('add' if use_normalization else 'mean')\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_normalization:\n",
    "            edge_weight = data.edge_norm * data.edge_weight\n",
    "            out = model(data.x.float(), data.edge_index.long(), edge_weight)\n",
    "            loss = F.nll_loss(out, data.y.long(), reduction='none')\n",
    "            loss = (loss * data.node_norm)[data.is_train].sum()\n",
    "        else:\n",
    "            out = model(data.x.float(), data.edge_index.long())\n",
    "            loss = F.nll_loss(out[data.is_train], data.y[data.is_train].long())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_nodes\n",
    "        total_examples += data.num_nodes\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.set_aggr('mean')\n",
    "\n",
    "    out = model(data.x.to(device).float(), data.edge_index.to(device).long())\n",
    "    pred = out.argmax(dim=-1)\n",
    "    correct = pred.eq(data.y.to(device))\n",
    "\n",
    "    accs = []\n",
    "    for _, mask in data('is_train', 'is_test'):\n",
    "        accs.append(correct[mask].sum().item() / mask.sum().item())\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    accs = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, Test: {accs[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5776f5fd9a49d1738b77bb79c5ee40cd664c402395f703d4208fe9f523e76f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
