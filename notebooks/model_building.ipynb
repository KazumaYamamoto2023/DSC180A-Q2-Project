{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4qh9m0b1ibjk7asj5ul6fmo9j0cd5mie', 1678066822, '2023-03-06 01:40:22')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pyTigerGraph as tg\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphSAGE, GCN\n",
    "from pyTigerGraph.gds.metrics import Accumulator, Accuracy, BinaryPrecision, BinaryRecall\n",
    "\n",
    "# import TigerGraph instance config\n",
    "os.chdir('../config/')\n",
    "with open('tigergraph.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Connection parameters\n",
    "hostName = config['host']\n",
    "secret = config['secret']\n",
    "\n",
    "conn = tg.TigerGraphConnection(host=hostName, gsqlSecret=secret, graphname=\"Ethereum\")\n",
    "conn.getToken(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting vertices...\n",
      "Vertex split finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# split nodes into train/test/validation sets\n",
    "split = conn.gds.vertexSplitter(is_train=0.6, is_test=0.2, is_valid=0.2)\n",
    "split.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train/test/validation data from TigerGraph\n",
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats=[\"in_degree\",\"out_degree\",\"total_sent\",\"send_min\",\"recv_amount\",\"recv_min\",\"pagerank\"],\n",
    "    v_out_labels=['label'],\n",
    "    v_extra_feats=['is_train','is_test','is_valid'],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True\n",
    ")\n",
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters for model training\n",
    "hp = {\"hidden_dim\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.05,\n",
    "    \"lr\": 0.0075,\n",
    "    \"l2_penalty\": 5e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(\n",
    "    in_channels=7,\n",
    "    hidden_channels=hp[\"hidden_dim\"],\n",
    "    num_layers=hp[\"num_layers\"],\n",
    "    out_channels=2,\n",
    "    dropout=hp[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Train Loss: 15.1281, Valid Loss: 16.4260, Train Accuracy: 0.5401, Valid Accuracy: 0.5422\n",
      "Epoch: 01, Train Loss: 2.4261, Valid Loss: 2.5215, Train Accuracy: 0.9927, Valid Accuracy: 0.9936\n",
      "Epoch: 02, Train Loss: 3.1896, Valid Loss: 3.4478, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 03, Train Loss: 3.7610, Valid Loss: 4.1130, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 04, Train Loss: 4.0655, Valid Loss: 4.6156, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 05, Train Loss: 4.2158, Valid Loss: 4.6833, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 06, Train Loss: 4.1204, Valid Loss: 4.7525, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 07, Train Loss: 4.1135, Valid Loss: 4.7026, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 08, Train Loss: 3.8753, Valid Loss: 4.4584, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 09, Train Loss: 3.7055, Valid Loss: 4.4024, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 10, Train Loss: 3.3287, Valid Loss: 4.2106, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 11, Train Loss: 3.0855, Valid Loss: 3.8982, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 12, Train Loss: 2.8449, Valid Loss: 3.7140, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 13, Train Loss: 2.2841, Valid Loss: 3.2005, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 14, Train Loss: 1.8762, Valid Loss: 2.6640, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 15, Train Loss: 1.4511, Valid Loss: 2.4225, Train Accuracy: 0.9944, Valid Accuracy: 0.9949\n",
      "Epoch: 16, Train Loss: 5.2240, Valid Loss: 5.9220, Train Accuracy: 0.9694, Valid Accuracy: 0.9725\n",
      "Epoch: 17, Train Loss: 1.5421, Valid Loss: 2.2701, Train Accuracy: 0.9944, Valid Accuracy: 0.9953\n",
      "Epoch: 18, Train Loss: 1.7775, Valid Loss: 2.6830, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n",
      "Epoch: 19, Train Loss: 2.3737, Valid Loss: 3.2088, Train Accuracy: 0.9947, Valid Accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "logs = {}\n",
    "data = data.to(device)\n",
    "for epoch in range(20):\n",
    "    # Train\n",
    "    model.train()\n",
    "    acc = Accuracy()\n",
    "    # Forward pass\n",
    "    out = model(data.x.float(), data.edge_index)\n",
    "    # Calculate loss\n",
    "    loss = F.cross_entropy(out[data.is_train].float(), data.y[data.is_train].long())\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Evaluate\n",
    "    val_acc = Accuracy()\n",
    "    with torch.no_grad():\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc.update(pred[data.is_train], data.y[data.is_train])\n",
    "        valid_loss = F.cross_entropy(out[data.is_valid].float(), data.y[data.is_valid].long())\n",
    "        val_acc.update(pred[data.is_valid], data.y[data.is_valid])\n",
    "    # Logging\n",
    "    logs[\"loss\"] = loss.item()\n",
    "    logs[\"val_loss\"] = valid_loss.item()\n",
    "    logs[\"acc\"] = acc.value\n",
    "    logs[\"val_acc\"] = val_acc.value\n",
    "    print(\n",
    "        \"Epoch: {:02d}, Train Loss: {:.4f}, Valid Loss: {:.4f}, Train Accuracy: {:.4f}, Valid Accuracy: {:.4f}\".format(\n",
    "            epoch, logs[\"loss\"], logs[\"val_loss\"], logs[\"acc\"], logs[\"val_acc\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare:\n",
    "# xgboost/SVM/knn\n",
    "# GCN\n",
    "# GraphSAGE\n",
    "# Node2vec\n",
    "# GAT?\n",
    "# Deep Graph Infomax?\n",
    "\n",
    "# our model is only predicting one class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0]), tensor([86622]))\n",
      "Accuracy: 0.9947\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-7a3f8e2a97c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "# model is overfit\n",
    "# perfectly predicting training data?\n",
    "model.eval()\n",
    "acc = Accuracy()\n",
    "precision = BinaryPrecision()\n",
    "recall = BinaryRecall()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x.float(), data.edge_index).argmax(dim=1)\n",
    "    print(pred.unique(return_counts= True))\n",
    "    acc.update(pred[data.is_test], data.y[data.is_test])\n",
    "    precision.update(pred[data.is_test], data.y[data.is_test])\n",
    "    recall.update(pred[data.is_test], data.y[data.is_test])\n",
    "print(\"Accuracy: {:.4f}\".format(acc.value))\n",
    "print(\"Precision: {:.4f}\".format(precision.value))\n",
    "print(\"Recall: {:.4f}\".format(recall.value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
